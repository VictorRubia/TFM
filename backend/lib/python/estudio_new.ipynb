{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heartpy as hp\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from scipy.signal import resample\n",
    "import pickle\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "from socket import timeout\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    file = urllib.request.urlopen(\"http://localhost:3000/activities/66/ppg_measures/\", timeout = 90)\n",
    "except timeout:\n",
    "    print('socket timed out')\n",
    "\n",
    "df = pd.read_json(file)\n",
    "\n",
    "timer = df['timer']\n",
    "signal = df['ppg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = hp.get_samplerate_datetime(timer, timeformat='%d/%m/%Y %H:%M:%S.%f')\n",
    "\n",
    "# Let's run it through a standard butterworth bandpass implementation to remove everything < 0.8 and > 3.5 Hz.\n",
    "filtered = hp.filter_signal(signal, [0.7, 3.5], sample_rate=sample_rate,\n",
    "                            order=3, filtertype='bandpass')\n",
    "\n",
    "resampled = resample(filtered, len(filtered) * 10)\n",
    "\n",
    "# #don't forget to compute the new sampling rate\n",
    "new_sample_rate = sample_rate * 10\n",
    "# #run HeartPy over a few segments, fingers crossed, and plot results of each\n",
    "\n",
    "numero_elementos = (int)(new_sample_rate * 60)\n",
    "\n",
    "a_splited = [resampled[x:x + numero_elementos] for x in range(0, len(resampled), numero_elementos)]\n",
    "\n",
    "resample_partio = np.array_split(resampled, numero_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data must not be constant.\n",
      "Data must not be constant.\n",
      "Data must not be constant.\n",
      "Data must not be constant.\n",
      "Data must not be constant.\n",
      "Data must not be constant.\n",
      "Data must not be constant.\n",
      "Data must not be constant.\n",
      "'mean_rr'\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "x = []\n",
    "contador = 0\n",
    "\n",
    "for s in a_splited:\n",
    "    try:\n",
    "        # Process the data with the updated process function\n",
    "        wd, m = hp.process(s, sample_rate=new_sample_rate, report_time=False,\n",
    "                           high_precision=True, clean_rr=True, calc_freq=True)\n",
    "        # Extract the measures from the measures dictionary 'm'\n",
    "        # Time-Domain Measures\n",
    "        mean_rr = m['mean_rr']\n",
    "        median_rr = m['median_rr']\n",
    "        sdnn = m['sdnn']  # Standard deviation of NN intervals (equivalent to SDRR)\n",
    "        rmssd = m['rmssd']\n",
    "        sdsd = m['sdsd']\n",
    "        sdnn_rmssd = sdnn / rmssd if rmssd != 0 else np.nan\n",
    "        hr = m['bpm']\n",
    "        pnn25 = m['pnn25']\n",
    "        pnn50 = m['pnn50']\n",
    "        sd1 = m['sd1']\n",
    "        sd2 = m['sd2']\n",
    "        skew_rr = m['SKEW']\n",
    "        kurt_rr = m['KURT']\n",
    "        hr_sqrt = np.sqrt(hr)\n",
    "\n",
    "        # Relative RR Measures\n",
    "        mean_rel_rr = m['MEAN_REL_RR']\n",
    "        median_rel_rr = m['MEDIAN_REL_RR']\n",
    "        sdrr_rel_rr = m['SDRR_REL_RR']\n",
    "        rmssd_rel_rr = m['RMSSD_REL_RR']\n",
    "        sdsd_rel_rr = m['SDSD_REL_RR']\n",
    "        sdrr_rmssd_rel_rr = m['SDRR_RMSSD_REL_RR']\n",
    "        skew_rel_rr = m['SKEW_REL_RR']\n",
    "        kurt_rel_rr = m['KURT_REL_RR']\n",
    "        mean_rr_mean_mean_rel_rr = np.mean([mean_rr, mean_rel_rr])\n",
    "\n",
    "        # Frequency-Domain Measures\n",
    "        vlf = m['vlf']\n",
    "        vlf_pct = m['vlf_pct']\n",
    "        lf = m['lf']\n",
    "        lf_pct = m['lf_pct']\n",
    "        lf_nu = m['lf_nu']\n",
    "        hf = m['hf']\n",
    "        hf_pct = m['hf_pct']\n",
    "        hf_nu = m['hf_nu']\n",
    "        tp = m['total_power']\n",
    "        lf_hf = m['lf/hf']\n",
    "        hf_lf = m['hf/lf']\n",
    "        hf_vlf = hf / vlf if vlf != 0 else np.nan\n",
    "        sd2_lf = sd2 * lf\n",
    "        hr_lf = hr * lf\n",
    "        hr_hf = hr * hf\n",
    "\n",
    "        # Nonlinear Measures\n",
    "        sampen = m['sampen']\n",
    "        higuci = m['higuci']\n",
    "\n",
    "        # Transformed Measures\n",
    "        mean_rr_log = m['MEAN_RR_LOG']\n",
    "        mean_rr_sqrt = m['MEAN_RR_SQRT']\n",
    "        tp_sqrt = m['TP_SQRT']\n",
    "        tp_log = m['TP_LOG']\n",
    "        vlf_log = m['VLF_LOG']\n",
    "        lf_log = m['LF_LOG']\n",
    "        hf_log = m['HF_LOG']\n",
    "        lf_hf_log = m['LF_HF_LOG']\n",
    "        rmssd_log = m['RMSSD_LOG']\n",
    "        sdrr_rmssd_log = m['SDRR_RMSSD_LOG']\n",
    "        pnn25_log = m['pNN25_LOG']\n",
    "        pnn50_log = m['pNN50_LOG']\n",
    "        sd1_log = m['SD1_LOG']\n",
    "        median_rel_rr_log = m['MEDIAN_REL_RR_LOG']\n",
    "        rmssd_rel_rr_log = m['RMSSD_REL_RR_LOG']\n",
    "        sdsd_rel_rr_log = m['SDSD_REL_RR_LOG']\n",
    "        kurt_square = m['KURT_SQUARE']\n",
    "        kurt_yeo_johnson = m['KURT_YEO_JONSON']\n",
    "        skew_yeo_johnson = m['SKEW_YEO_JONSON']\n",
    "        mean_rel_rr_yeo_johnson = m['MEAN_REL_RR_YEO_JONSON']\n",
    "        skew_rel_rr_yeo_johnson = m['SKEW_REL_RR_YEO_JONSON']\n",
    "        lf_boxcox = m['LF_BOXCOX']\n",
    "        hf_boxcox = m['HF_BOXCOX']\n",
    "        sd1_boxcox = m['SD1_BOXCOX']\n",
    "\n",
    "        # List of measures to check for NaN values\n",
    "        measures_to_check = [\n",
    "            mean_rr, median_rr, sdnn, rmssd, sdsd, sdnn_rmssd, hr, pnn25, pnn50, sd1, sd2,\n",
    "            skew_rr, kurt_rr, mean_rel_rr, median_rel_rr, sdrr_rel_rr, rmssd_rel_rr, sdsd_rel_rr,\n",
    "            sdrr_rmssd_rel_rr, skew_rel_rr, kurt_rel_rr, vlf, vlf_pct, lf, lf_pct, lf_nu,\n",
    "            hf, hf_pct, hf_nu, tp, lf_hf, hf_lf, sampen, higuci, mean_rr_log, mean_rr_sqrt,\n",
    "            tp_sqrt, tp_log, vlf_log, lf_log, hf_log, lf_hf_log, rmssd_log, sdrr_rmssd_log,\n",
    "            pnn25_log, pnn50_log, sd1_log, median_rel_rr_log, rmssd_rel_rr_log, sdsd_rel_rr_log,\n",
    "            kurt_square, kurt_yeo_johnson, skew_yeo_johnson, mean_rel_rr_yeo_johnson,\n",
    "            skew_rel_rr_yeo_johnson, lf_boxcox, hf_boxcox, sd1_boxcox, hr_sqrt,\n",
    "            mean_rr_mean_mean_rel_rr, sd2_lf, hr_lf, hr_hf, hf_vlf\n",
    "        ]\n",
    "\n",
    "        # Check if any of the measures are NaN\n",
    "        if not any(math.isnan(value) for value in measures_to_check):\n",
    "            # Append the data to the list 'data' if all measures are valid\n",
    "            data.append([\n",
    "                datetime.strptime(timer[0], \"%d/%m/%Y %H:%M:%S.%f\") + timedelta(minutes=1 * contador),\n",
    "                mean_rr, median_rr, sdnn, rmssd, sdsd, sdnn_rmssd, hr, pnn25, pnn50, sd1, sd2,\n",
    "                skew_rr, kurt_rr, mean_rel_rr, median_rel_rr, sdrr_rel_rr, rmssd_rel_rr,\n",
    "                sdsd_rel_rr, sdrr_rmssd_rel_rr, skew_rel_rr, kurt_rel_rr, vlf, vlf_pct, lf,\n",
    "                lf_pct, lf_nu, hf, hf_pct, hf_nu, tp, lf_hf, hf_lf, sampen, higuci, mean_rr_log,\n",
    "                mean_rr_sqrt, tp_sqrt, tp_log, vlf_log, lf_log, hf_log, lf_hf_log, rmssd_log,\n",
    "                sdrr_rmssd_log, pnn25_log, pnn50_log, sd1_log, median_rel_rr_log, rmssd_rel_rr_log,\n",
    "                sdsd_rel_rr_log, kurt_square, kurt_yeo_johnson, skew_yeo_johnson,\n",
    "                mean_rel_rr_yeo_johnson, skew_rel_rr_yeo_johnson, lf_boxcox, hf_boxcox, sd1_boxcox,\n",
    "                hr_sqrt, mean_rr_mean_mean_rel_rr, sd2_lf, hr_lf, hr_hf, hf_vlf\n",
    "            ])\n",
    "        else:\n",
    "            # Handle the case where measures are NaN\n",
    "            x.append({\n",
    "                \"date\": (datetime.strptime(timer[0], \"%d/%m/%Y %H:%M:%S.%f\") + timedelta(minutes=1 * contador)).strftime(\"%d/%m/%Y %H:%M\"),\n",
    "                \"measure\": -1\n",
    "            })\n",
    "        \n",
    "        # Increment the counter\n",
    "        contador += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during processing\n",
    "        x.append({\n",
    "            \"date\": (datetime.strptime(timer[0], \"%d/%m/%Y %H:%M:%S.%f\") + timedelta(minutes=1 * contador)).strftime(\"%d/%m/%Y %H:%M\"),\n",
    "            \"measure\": -1,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        contador += 1\n",
    "        print(e)\n",
    "\n",
    "# Define the header for the DataFrame\n",
    "header = [\n",
    "    'DATETIME', 'MEAN_RR', 'MEDIAN_RR', 'SDRR', 'RMSSD', 'SDSD', 'SDRR_RMSSD', 'HR', 'pNN25', 'pNN50',\n",
    "    'SD1', 'SD2', 'SKEW', 'KURT', 'MEAN_REL_RR', 'MEDIAN_REL_RR', 'SDRR_REL_RR', 'RMSSD_REL_RR',\n",
    "    'SDSD_REL_RR', 'SDRR_RMSSD_REL_RR', 'SKEW_REL_RR', 'KURT_REL_RR', 'VLF', 'VLF_PCT', 'LF',\n",
    "    'LF_PCT', 'LF_NU', 'HF', 'HF_PCT', 'HF_NU', 'TP', 'LF_HF', 'HF_LF', 'sampen', 'higuci',\n",
    "    'MEAN_RR_LOG', 'MEAN_RR_SQRT', 'TP_SQRT', 'TP_LOG', 'VLF_LOG', 'LF_LOG', 'HF_LOG', 'LF_HF_LOG',\n",
    "    'RMSSD_LOG', 'SDRR_RMSSD_LOG', 'pNN25_LOG', 'pNN50_LOG', 'SD1_LOG', 'MEDIAN_REL_RR_LOG',\n",
    "    'RMSSD_REL_RR_LOG', 'SDSD_REL_RR_LOG', 'KURT_SQUARE', 'KURT_YEO_JONSON', 'SKEW_YEO_JONSON',\n",
    "    'MEAN_REL_RR_YEO_JONSON', 'SKEW_REL_RR_YEO_JONSON', 'LF_BOXCOX', 'HF_BOXCOX', 'SD1_BOXCOX',\n",
    "    'HR_SQRT', 'MEAN_RR_MEAN_MEAN_REL_RR', 'SD2_LF', 'HR_LF', 'HR_HF', 'HF_VLF'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "datos_a_procesar = pd.DataFrame(data, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>MEAN_RR</th>\n",
       "      <th>MEDIAN_RR</th>\n",
       "      <th>SDRR</th>\n",
       "      <th>RMSSD</th>\n",
       "      <th>SDSD</th>\n",
       "      <th>SDRR_RMSSD</th>\n",
       "      <th>HR</th>\n",
       "      <th>pNN25</th>\n",
       "      <th>pNN50</th>\n",
       "      <th>...</th>\n",
       "      <th>SKEW_REL_RR_YEO_JONSON</th>\n",
       "      <th>LF_BOXCOX</th>\n",
       "      <th>HF_BOXCOX</th>\n",
       "      <th>SD1_BOXCOX</th>\n",
       "      <th>HR_SQRT</th>\n",
       "      <th>MEAN_RR_MEAN_MEAN_REL_RR</th>\n",
       "      <th>SD2_LF</th>\n",
       "      <th>HR_LF</th>\n",
       "      <th>HR_HF</th>\n",
       "      <th>HF_VLF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DATETIME, MEAN_RR, MEDIAN_RR, SDRR, RMSSD, SDSD, SDRR_RMSSD, HR, pNN25, pNN50, SD1, SD2, SKEW, KURT, MEAN_REL_RR, MEDIAN_REL_RR, SDRR_REL_RR, RMSSD_REL_RR, SDSD_REL_RR, SDRR_RMSSD_REL_RR, SKEW_REL_RR, KURT_REL_RR, VLF, VLF_PCT, LF, LF_PCT, LF_NU, HF, HF_PCT, HF_NU, TP, LF_HF, HF_LF, sampen, higuci, MEAN_RR_LOG, MEAN_RR_SQRT, TP_SQRT, TP_LOG, VLF_LOG, LF_LOG, HF_LOG, LF_HF_LOG, RMSSD_LOG, SDRR_RMSSD_LOG, pNN25_LOG, pNN50_LOG, SD1_LOG, MEDIAN_REL_RR_LOG, RMSSD_REL_RR_LOG, SDSD_REL_RR_LOG, KURT_SQUARE, KURT_YEO_JONSON, SKEW_YEO_JONSON, MEAN_REL_RR_YEO_JONSON, SKEW_REL_RR_YEO_JONSON, LF_BOXCOX, HF_BOXCOX, SD1_BOXCOX, HR_SQRT, MEAN_RR_MEAN_MEAN_REL_RR, SD2_LF, HR_LF, HR_HF, HF_VLF]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 65 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_a_procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "x = []\n",
    "contador = 0\n",
    "for s in a_splited:\n",
    "    try:\n",
    "        wd, m = hp.process(s, sample_rate=new_sample_rate, report_time=False,\n",
    "                           high_precision=True, clean_rr=True)\n",
    "        sdsd = m['sdsd']\n",
    "        rmssd = m['rmssd']\n",
    "        hr = m['bpm']\n",
    "        pnn50 = m['pnn50']\n",
    "        sd1 = m['sd1']\n",
    "        sd2 = m['sd2']\n",
    "        mean_rr = m['ibi']\n",
    "        median_rr = np.median(m['ibi'])\n",
    "        sdnn = m['sdnn']\n",
    "        sdnn_rmssd = sdnn/rmssd\n",
    "\n",
    "        if not math.isnan(sdsd) and not math.isnan(rmssd) and not math.isnan(hr) and not math.isnan(hr) and not math.isnan(pnn50) and not math.isnan(sd1) and not math.isnan(sd2) and not math.isnan(mean_rr) and not math.isnan(mean_rr) and not math.isnan(median_rr) and not math.isnan(sdnn) and not math.isnan(sdnn_rmssd):\n",
    "            data.append([datetime.strptime(timer[0], \"%d/%m/%Y %H:%M:%S.%f\") + timedelta(minutes=1*contador) ,mean_rr, median_rr, sdnn, rmssd, sdsd, sdnn_rmssd, hr, pnn50, sd1, sd2, m['MEAN_REL_RR'], m['MEDIAN_REL_RR'], m['SDRR_REL_RR'], m['RMSSD_REL_RR'], m['SDRR_RMSSD_REL_RR']])\n",
    "\n",
    "        contador = contador + 1\n",
    "    except Exception as e:\n",
    "        x.append({\n",
    "            \"date\": (datetime.strptime(timer[0], \"%d/%m/%Y %H:%M:%S.%f\") + timedelta(minutes=1*contador)).strftime(\"%d/%m/%Y %H:%M\"),\n",
    "            \"measure\": -1\n",
    "        })\n",
    "\n",
    "header = ['DATETIME', 'MEAN_RR', 'MEDIAN_RR', 'SDRR', 'RMSSD', 'SDSD', 'SDRR_RMSSD', 'HR', 'pNN50', 'SD1', 'SD2', 'MEAN_REL_RR', 'MEDIAN_REL_RR', 'SDRR_REL_RR', 'RMSSD_REL_RR', 'SDRR_RMSSD_REL_RR']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
